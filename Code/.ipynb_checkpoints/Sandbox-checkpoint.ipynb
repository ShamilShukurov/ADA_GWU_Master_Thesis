{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34c306b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e09c56de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import *\n",
    "from datasets import *\n",
    "from utils import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b93b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Adult...\n",
      "Adult fetched successfully\n",
      "Processing cc_fraud_1...\n",
      "cc_fraud_1 fetched successfully\n",
      "Processing cc_fraud_2...\n",
      "cc_fraud_2 fetched successfully\n",
      "Processing cc_fraud_3...\n",
      "cc_fraud_3 fetched successfully\n",
      "Processing cc_fraud_4...\n",
      "cc_fraud_4 fetched successfully\n",
      "Processing cc_fraud_05...\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "dfs = fetch_all_datasets()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef41bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "439.3346195220947//60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8178b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dfs:\n",
    "    print(10*\"=\"+d.name+10*\"=\")\n",
    "    print(get_stats(pd.concat([d.X_train, d.y_train], axis=1), d.target_col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf074f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_dfs = [fetch_dataset('PTP_Data')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(exp_dfs[0].X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69406fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(exp_dfs[0].X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9739e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning_algorithms import *\n",
    "clfs = [XGBoostClassifier(),LogisticRegressionClassifier(),SVMClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aac0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_experiment(dfs, clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ddbf171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shami\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done. Time taken: 0.51 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.992824</td>\n",
       "      <td>0.919552</td>\n",
       "      <td>0.860503</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.997559</td>\n",
       "      <td>0.512858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.993692</td>\n",
       "      <td>0.927944</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.997572</td>\n",
       "      <td>0.512858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Sample  Accuracy  F1 Score  Precision    Recall  AUC Score  \\\n",
       "0   XGB  Train  0.992824  0.919552   0.860503  0.987302   0.997559   \n",
       "1   XGB   Test  0.993692  0.927944   0.874172  0.988764   0.997572   \n",
       "\n",
       "   Training Time (s)  \n",
       "0           0.512858  \n",
       "1           0.512858  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alg = XGBoostClassifier()\n",
    "# alg.train_eval(exp_dfs[0].X_train, exp_dfs[0].y_train,\n",
    "#                                           exp_dfs[0].X_test, exp_dfs[0].y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f4bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd6a3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probas_train = alg.predict(exp_dfs[0].X_train) # Assuming binary classification\n",
    "# probas_test = alg.predict(exp_dfs[0].X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e428307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     87220\n",
      "           1       0.86      0.99      0.92      3780\n",
      "\n",
      "    accuracy                           0.99     91000\n",
      "   macro avg       0.93      0.99      0.96     91000\n",
      "weighted avg       0.99      0.99      0.99     91000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(exp_dfs[0].y_train, probas_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852e797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
